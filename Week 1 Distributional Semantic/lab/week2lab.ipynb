{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HSHLlhLoIqm"
      },
      "source": [
        "# Lab 2: Semantic Similarity Using WordNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6BhyrzXoIqx"
      },
      "source": [
        "I am running Python 3.10.12  Which version are you running?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA33bNdNoIqy",
        "outputId": "dea3cfd5-a1e4-40c9-e2e7-97334a80b0c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfAAXI4CoIq0"
      },
      "source": [
        "## 1. Getting Started\n",
        "\n",
        "If you haven't used nltk before, you will need to run the following cell and download resources.  You will need:\n",
        "\n",
        "*   wordnet\n",
        "*   wordnet_ic\n",
        "*   omw-1.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSvw5nQAoIq0",
        "outputId": "a1eb0cfe-f3ac-4369-e8b9-adc244a39914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet_ic.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download('wordnet_ic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PmvA2psQoIq2"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import wordnet_ic as wn_ic\n",
        "from nltk.corpus import  lin_thesaurus as lin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrpgr6dCoIq3"
      },
      "source": [
        "## 2 Useful WN Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgDy82sqcPnL"
      },
      "source": [
        "Look at the code in the cells below.  Write notes as to what is being returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I48Nuzsb92s",
        "outputId": "8e6bffab-e21c-4124-9398-7e47109b444c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('book.n.01'),\n",
              " Synset('book.n.02'),\n",
              " Synset('record.n.05'),\n",
              " Synset('script.n.01'),\n",
              " Synset('ledger.n.01'),\n",
              " Synset('book.n.06'),\n",
              " Synset('book.n.07'),\n",
              " Synset('koran.n.01'),\n",
              " Synset('bible.n.01'),\n",
              " Synset('book.n.10'),\n",
              " Synset('book.n.11'),\n",
              " Synset('book.v.01'),\n",
              " Synset('reserve.v.04'),\n",
              " Synset('book.v.03'),\n",
              " Synset('book.v.04')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "wn.synsets(\"book\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT9SnNt9oYUi"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD5q1lDhoIq4",
        "outputId": "07c0e55c-1c04-4142-9bdf-dd0c28afbbbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(wn.synsets(\"book\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TWoA75McBAq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhtFKEs8oIq6",
        "outputId": "e4a9c9f6-8b6d-4e75-8477-19ae8f6bcd5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "wn.synsets(\"book\", wn.ADV)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv5efmqecbI9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "46qdZbPjoIq7",
        "outputId": "e0159fdf-b583-4b29-aeab-162379b6f5d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'physical objects consisting of a number of pages bound together'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "asynset=wn.synsets(\"book\",wn.NOUN)[1]\n",
        "asynset.definition()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets(\"book\",wn.NOUN)[1]"
      ],
      "metadata": {
        "id": "7DfJ9JiTIudj",
        "outputId": "18952343-a2f8-4267-a467-618ef5719098",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Synset('book.n.02')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX_62pBWcb8U"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvSQNZ1_oIq8",
        "outputId": "e85728cf-755d-46ca-8c8d-415ab748965a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('coffee-table_book.n.01'),\n",
              " Synset('folio.n.03'),\n",
              " Synset('sketchbook.n.01'),\n",
              " Synset('novel.n.02'),\n",
              " Synset('journal.n.04'),\n",
              " Synset('paperback_book.n.01'),\n",
              " Synset('hardback.n.01'),\n",
              " Synset('order_book.n.02'),\n",
              " Synset('picture_book.n.01'),\n",
              " Synset('album.n.02'),\n",
              " Synset('notebook.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "asynset.hyponyms()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15r6gJ9UHiEv"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yJx16-KxHiEv",
        "outputId": "aff7f8e4-0a2f-4a99-8b2a-0ce6b356ab97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('product.n.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "asynset.hypernyms()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO0wCrt0ccwM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "asynset.hypernyms().hyponyms()"
      ],
      "metadata": {
        "id": "-a7I8HiSJFCa",
        "outputId": "cbb7e6c6-f044-48a1-b3fd-d1292fb028c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'hyponyms'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-491161526.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0masynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypernyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyponyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'hyponyms'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqtM8hW9oIq9",
        "outputId": "3f7a8904-65f2-4fb5-c4fe-03e45ceb4cdd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('magazine.n.02'),\n",
              " Synset('book.n.02'),\n",
              " Synset('book.n.11'),\n",
              " Synset('inspiration.n.02'),\n",
              " Synset('deliverable.n.01'),\n",
              " Synset('by-product.n.02'),\n",
              " Synset('work.n.02'),\n",
              " Synset('output.n.05'),\n",
              " Synset('yield.n.03'),\n",
              " Synset('movie.n.01'),\n",
              " Synset('newspaper.n.03'),\n",
              " Synset('end_product.n.01'),\n",
              " Synset('turnery.n.02'),\n",
              " Synset('job.n.04')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "asynset.hypernyms()[0].hyponyms()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2rXmptkcdvy"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq4xbOUMoIq-",
        "outputId": "8f0a1a1f-7d67-47d6-f54d-e25151e2cee9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6062360082744072"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "brown_ic=wn_ic.ic('ic-brown.dat')\n",
        "asynset.lin_similarity(asynset.hypernyms()[0].hyponyms()[8],brown_ic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9335uFLyceo3"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvAABmvWHiEv"
      },
      "source": [
        "# 2.1 Q1\n",
        "Write a function to return the path similarity of two nouns.  Remember this is the maximum similarity of all of the possible pairings of the two nouns.  Make sure you test it.  For (chicken, car) the correct answer is 0.0909 (to 3 SF)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets(\"car\")"
      ],
      "metadata": {
        "id": "kOrCR0i5SVIv",
        "outputId": "bcbda5eb-2e5e-42cf-ed30-11835722d6bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('car.n.01'),\n",
              " Synset('car.n.02'),\n",
              " Synset('car.n.03'),\n",
              " Synset('car.n.04'),\n",
              " Synset('cable_car.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets(\"chicken\")"
      ],
      "metadata": {
        "id": "QHMjKCwFSZ7W",
        "outputId": "9b2b76f8-b6f7-4046-b7cf-b1f25a0a6a62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('chicken.n.01'),\n",
              " Synset('chicken.n.02'),\n",
              " Synset('wimp.n.01'),\n",
              " Synset('chicken.n.04'),\n",
              " Synset('chicken.s.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "5Lf3kfnGHiEv"
      },
      "outputs": [],
      "source": [
        "def find_path_similarity(word1, word2):\n",
        "\n",
        "  possible_similarities = []\n",
        "\n",
        "  word1_synsets = wn.synsets(word1)\n",
        "  word2_synsets = wn.synsets(word2)\n",
        "\n",
        "  for i in range(len(word1_synsets)):\n",
        "    for j in range(len(word2_synsets)):\n",
        "      sim = wn.path_similarity(word1_synsets[i], word2_synsets[j])\n",
        "      possible_similarities.append(sim)\n",
        "\n",
        "\n",
        "  return max(possible_similarities)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_path_similarity(\"chicken\", \"car\")"
      ],
      "metadata": {
        "id": "eJBnmgdTK0vI",
        "outputId": "d8ac8bd3-b160-4d49-f55d-bb07e612b5b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09090909090909091"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1c_IYS2HiEv"
      },
      "source": [
        "# 2.1 Q2\n",
        "Generalise your function so that you have an extra (optional) parameter which you can use to select the WordNet similarity measure e.g., res_similarity and lin_similarity.  Make sure you test it.  For the pair (chicken,car), the correct answer for res_similarity is 1.53 (to 3SF) and the correct answer for lin_similarity is 0.179"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similarity1(word1, word2, sim_measure):\n",
        "\n",
        "  possible_similarities = []\n",
        "\n",
        "  word1_synsets = wn.synsets(word1)\n",
        "  word2_synsets = wn.synsets(word2)\n",
        "  brown_ic=wn_ic.ic(\"ic-brown.dat\")\n",
        "\n",
        "  for i in word1_synsets:\n",
        "    for j in word2_synsets:\n",
        "      if sim_measure == \"res_similarity\":\n",
        "\n",
        "        sim = wn.res_similarity(i, j, brown_ic)\n",
        "        possible_similarities.append(sim)\n",
        "\n",
        "      if sim_measure == \"lin_similarity\":\n",
        "\n",
        "        sim = wn.lin_similarity(i, j, brown_ic)\n",
        "        possible_similarities.append(sim)\n",
        "\n",
        "  return max(possible_similarities)"
      ],
      "metadata": {
        "id": "Bm4qUBRuR1jO"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "3JCXhtG-HiEv"
      },
      "outputs": [],
      "source": [
        "def find_similarity(word1, word2, sim_measure):\n",
        "\n",
        "  possible_similarities = []\n",
        "\n",
        "  word1_synsets = wn.synsets(word1, wn.NOUN)\n",
        "  word2_synsets = wn.synsets(word2, wn.NOUN)\n",
        "  brown_ic=wn_ic.ic(\"ic-brown.dat\")\n",
        "\n",
        "  for i in word1_synsets:\n",
        "    for j in word2_synsets:\n",
        "\n",
        "      if sim_measure == \"path_similarity\":\n",
        "\n",
        "        sim = wn.path_similarity(i, j)\n",
        "        possible_similarities.append(sim)\n",
        "\n",
        "      if sim_measure == \"res_similarity\":\n",
        "\n",
        "        sim = wn.res_similarity(i, j, brown_ic)\n",
        "        possible_similarities.append(sim)\n",
        "\n",
        "      if sim_measure == \"lin_similarity\":\n",
        "\n",
        "        sim = wn.lin_similarity(i, j, brown_ic)\n",
        "        possible_similarities.append(sim)\n",
        "\n",
        "  return max(possible_similarities)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_similarity1(\"chicken\", \"car\", \"res_similarity\")"
      ],
      "metadata": {
        "id": "VfZXKI95R5t-",
        "outputId": "97c8a11c-8f34-4790-f335-241086b27b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "WordNetError",
          "evalue": "Computing the least common subsumer requires Synset('chicken.s.01') and Synset('car.n.01') to have the same part of speech.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWordNetError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3090541075.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfind_similarity1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chicken\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"car\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"res_similarity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4248555733.py\u001b[0m in \u001b[0;36mfind_similarity1\u001b[0;34m(word1, word2, sim_measure)\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msim_measure\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"res_similarity\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrown_ic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mpossible_similarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mres_similarity\u001b[0;34m(self, synset1, synset2, ic, verbose)\u001b[0m\n\u001b[1;32m   1996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mres_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msynset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m     \u001b[0mres_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mres_similarity\u001b[0;34m(self, other, ic, verbose)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         \"\"\"\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m         \u001b[0mic1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcs_ic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lcs_ic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlcs_ic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m_lcs_ic\u001b[0;34m(synset1, synset2, ic, verbose)\u001b[0m\n\u001b[1;32m   2433\u001b[0m     \"\"\"\n\u001b[1;32m   2434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msynset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msynset2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2435\u001b[0;31m         raise WordNetError(\n\u001b[0m\u001b[1;32m   2436\u001b[0m             \u001b[0;34m\"Computing the least common subsumer requires \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m             \u001b[0;34m\"%s and %s to have the same part of speech.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msynset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWordNetError\u001b[0m: Computing the least common subsumer requires Synset('chicken.s.01') and Synset('car.n.01') to have the same part of speech."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_similarity(\"chicken\", \"car\", \"path_similarity\")"
      ],
      "metadata": {
        "id": "JY8a2N-STPCW",
        "outputId": "95760892-0f06-487d-b65f-1ed24777249b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09090909090909091"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "qZiqVbdyHiEv",
        "outputId": "cdebe933-4686-4d41-abb4-d40839a2b78c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5318337432196856"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "find_similarity(\"chicken\", \"car\", \"res_similarity\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_similarity(\"chicken\", \"car\", \"lin_similarity\")"
      ],
      "metadata": {
        "id": "c_9OIYuhRvKY",
        "outputId": "5b9924b7-7c20-4894-e524-184158122bbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17900106582025765"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To compute Lin similarity and resnik similarity, we can only use \"NOUN\"s**"
      ],
      "metadata": {
        "id": "MmsYPQ95SgL2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5Ukx9h9oIq_"
      },
      "source": [
        "## 3 Human Synonymy Judgments\n",
        "\n",
        "### 3.1\n",
        "Read in mcdata.csv and store it in an appropriate format so that you can obtain a list of pairs of the nouns and the score associated with each pair.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GRbcpJhHiEv"
      },
      "source": [
        "Again, many ways to complete this one.  I would encourage the use of the csv package (either with dialect = 'excel' or the delimiter and quotechar explicitly set) to avoid future problems when reading csv files which have commas in the fields.  Pandas is a good choice here and will make the correlations easier later (but just storing a list of triples (i.e., mcdata in the code below) is fine too)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDG0Z6zpplJM"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_df = []\n",
        "with open(\"sample_data/mcdata.csv\") as file:\n",
        "  for i in file:\n",
        "    w1, w2, sim = i.split(\",\")\n",
        "    list_df.append([w1, w2, sim.strip()])\n",
        "\n",
        "list_df"
      ],
      "metadata": {
        "id": "FeZgDNjNVuHf",
        "outputId": "23c111fc-d6fe-4a0f-90f9-112a95d11cb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['asylum', 'madhouse', '3.61'],\n",
              " ['bird', 'cock', '3.05'],\n",
              " ['bird', 'crane', '2.97'],\n",
              " ['boy', 'lad', '3.76'],\n",
              " ['brother', 'monk', '2.82'],\n",
              " ['car', 'automobile', '3.92'],\n",
              " ['cemetery', 'woodland', '0.95'],\n",
              " ['chord', 'smile', '0.13'],\n",
              " ['coast', 'forest', '0.42'],\n",
              " ['coast', 'hill', '0.87'],\n",
              " ['coast', 'shore', '3.7'],\n",
              " ['crane', 'implement', '1.68'],\n",
              " ['food', 'fruit', '3.08'],\n",
              " ['food', 'rooster', '0.89'],\n",
              " ['forest', 'graveyard', '0.84'],\n",
              " ['furnace', 'stove', '3.11'],\n",
              " ['gem', 'jewel', '3.84'],\n",
              " ['glass', 'magician', '0.11'],\n",
              " ['journey', 'car', '1.16'],\n",
              " ['journey', 'voyage', '3.84'],\n",
              " ['lad', 'brother', '1.66'],\n",
              " ['lad', 'wizard', '0.42'],\n",
              " ['magician', 'wizard', '3.5'],\n",
              " ['midday', 'noon', '3.42'],\n",
              " ['monk', 'oracle', '1.1'],\n",
              " ['monk', 'slave', '0.55'],\n",
              " ['noon', 'string', '0.08'],\n",
              " ['rooster', 'voyage', '0.08'],\n",
              " ['shore', 'woodland', '0.63'],\n",
              " ['tool', 'implement', '1.68']]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "esiswHElHiEv",
        "outputId": "38b07d17-9e51-41dd-dab7-344355054e87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       word1       word2   sim\n",
              "0     asylum    madhouse  3.61\n",
              "1       bird        cock  3.05\n",
              "2       bird       crane  2.97\n",
              "3        boy         lad  3.76\n",
              "4    brother        monk  2.82\n",
              "5        car  automobile  3.92\n",
              "6   cemetery    woodland  0.95\n",
              "7      chord       smile  0.13\n",
              "8      coast      forest  0.42\n",
              "9      coast        hill  0.87\n",
              "10     coast       shore  3.70\n",
              "11     crane   implement  1.68\n",
              "12      food       fruit  3.08\n",
              "13      food     rooster  0.89\n",
              "14    forest   graveyard  0.84\n",
              "15   furnace       stove  3.11\n",
              "16       gem       jewel  3.84\n",
              "17     glass    magician  0.11\n",
              "18   journey         car  1.16\n",
              "19   journey      voyage  3.84\n",
              "20       lad     brother  1.66\n",
              "21       lad      wizard  0.42\n",
              "22  magician      wizard  3.50\n",
              "23    midday        noon  3.42\n",
              "24      monk      oracle  1.10\n",
              "25      monk       slave  0.55\n",
              "26      noon      string  0.08\n",
              "27   rooster      voyage  0.08\n",
              "28     shore    woodland  0.63\n",
              "29      tool   implement  1.68"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7dc92e5d-20bb-43e6-850e-c5a7db16c9d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word1</th>\n",
              "      <th>word2</th>\n",
              "      <th>sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>asylum</td>\n",
              "      <td>madhouse</td>\n",
              "      <td>3.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bird</td>\n",
              "      <td>cock</td>\n",
              "      <td>3.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bird</td>\n",
              "      <td>crane</td>\n",
              "      <td>2.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>boy</td>\n",
              "      <td>lad</td>\n",
              "      <td>3.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>brother</td>\n",
              "      <td>monk</td>\n",
              "      <td>2.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>car</td>\n",
              "      <td>automobile</td>\n",
              "      <td>3.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>cemetery</td>\n",
              "      <td>woodland</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>chord</td>\n",
              "      <td>smile</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>coast</td>\n",
              "      <td>forest</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>coast</td>\n",
              "      <td>hill</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>coast</td>\n",
              "      <td>shore</td>\n",
              "      <td>3.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>crane</td>\n",
              "      <td>implement</td>\n",
              "      <td>1.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>food</td>\n",
              "      <td>fruit</td>\n",
              "      <td>3.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>food</td>\n",
              "      <td>rooster</td>\n",
              "      <td>0.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>forest</td>\n",
              "      <td>graveyard</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>furnace</td>\n",
              "      <td>stove</td>\n",
              "      <td>3.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>gem</td>\n",
              "      <td>jewel</td>\n",
              "      <td>3.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>glass</td>\n",
              "      <td>magician</td>\n",
              "      <td>0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>journey</td>\n",
              "      <td>car</td>\n",
              "      <td>1.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>journey</td>\n",
              "      <td>voyage</td>\n",
              "      <td>3.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>lad</td>\n",
              "      <td>brother</td>\n",
              "      <td>1.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>lad</td>\n",
              "      <td>wizard</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>magician</td>\n",
              "      <td>wizard</td>\n",
              "      <td>3.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>midday</td>\n",
              "      <td>noon</td>\n",
              "      <td>3.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>monk</td>\n",
              "      <td>oracle</td>\n",
              "      <td>1.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>monk</td>\n",
              "      <td>slave</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>noon</td>\n",
              "      <td>string</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>rooster</td>\n",
              "      <td>voyage</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>shore</td>\n",
              "      <td>woodland</td>\n",
              "      <td>0.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>tool</td>\n",
              "      <td>implement</td>\n",
              "      <td>1.68</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7dc92e5d-20bb-43e6-850e-c5a7db16c9d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7dc92e5d-20bb-43e6-850e-c5a7db16c9d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7dc92e5d-20bb-43e6-850e-c5a7db16c9d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_00803f53-09a6-4639-a29f-a31d52579c87\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_00803f53-09a6-4639-a29f-a31d52579c87 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"word1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"lad\",\n          \"food\",\n          \"asylum\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"forest\",\n          \"jewel\",\n          \"madhouse\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sim\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4199789945022379,\n        \"min\": 0.08,\n        \"max\": 3.92,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          0.42,\n          3.84,\n          3.61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"sample_data/mcdata.csv\", header=None)\n",
        "df.columns = [\"word1\", \"word2\", \"sim\"]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp6Wcd1woIrA"
      },
      "source": [
        "### 3.2\n",
        "\n",
        "Calculate the similarity score for each pair of nouns using at least 2 semantic similarity measures."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[0,1]\n"
      ],
      "metadata": {
        "id": "khmlpoQ8bAXN",
        "outputId": "18348658-416f-4f8f-86fe-09e73bfbc2b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'madhouse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for x in range(df.shape[0]):\n",
        "\n",
        "\n",
        "  if wn.synsets(df.iloc[x,1], wn.NOUN) != 0:\n",
        "    count += 1\n",
        "\n",
        "count\n"
      ],
      "metadata": {
        "id": "PShUkOmrYh2m",
        "outputId": "e92068f4-b04d-457a-9fa5-d8856f2e2480",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2_noun_syn = wn.synsets(df.iloc[0,1], wn.NOUN)[0]\n",
        "word2_noun_syn"
      ],
      "metadata": {
        "id": "OnDRoJHybNw9",
        "outputId": "442e7c2a-9c52-4015-fe69-9b5f639bf73f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('bedlam.n.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(df.shape[0]):\n",
        "  find_similarity1(df.iloc[x,0], df.iloc[x,1], \"lin_similarity\")"
      ],
      "metadata": {
        "id": "DrHVq59fbVCt",
        "outputId": "eb9d1358-10f5-497e-f174-67631169d7d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "error",
          "ename": "WordNetError",
          "evalue": "Computing the least common subsumer requires Synset('bird.n.01') and Synset('cock.v.01') to have the same part of speech.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWordNetError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-875973619.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mfind_similarity1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lin_similarity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4248555733.py\u001b[0m in \u001b[0;36mfind_similarity1\u001b[0;34m(word1, word2, sim_measure)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msim_measure\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"lin_similarity\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrown_ic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mpossible_similarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mlin_similarity\u001b[0;34m(self, synset1, synset2, ic, verbose)\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlin_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msynset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m     \u001b[0mlin_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mlin_similarity\u001b[0;34m(self, other, ic, verbose)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \"\"\"\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         \u001b[0mic1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcs_ic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lcs_ic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlcs_ic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mic1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mic2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m_lcs_ic\u001b[0;34m(synset1, synset2, ic, verbose)\u001b[0m\n\u001b[1;32m   2433\u001b[0m     \"\"\"\n\u001b[1;32m   2434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msynset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msynset2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2435\u001b[0;31m         raise WordNetError(\n\u001b[0m\u001b[1;32m   2436\u001b[0m             \u001b[0;34m\"Computing the least common subsumer requires \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m             \u001b[0;34m\"%s and %s to have the same part of speech.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msynset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWordNetError\u001b[0m: Computing the least common subsumer requires Synset('bird.n.01') and Synset('cock.v.01') to have the same part of speech."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape[0]"
      ],
      "metadata": {
        "id": "YSohcl93ZQgu",
        "outputId": "565e9820-6c4b-4ba3-8996-1b863c01f7bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "rxu_BbByHiEv",
        "outputId": "e0f1cd1d-00f6-4e5b-8e49-9454c0918ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "WordNetError",
          "evalue": "Computing the least common subsumer requires Synset('bird.n.01') and Synset('cock.v.01') to have the same part of speech.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWordNetError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2073725642.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_similarity1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lin_similarity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mlin_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4248555733.py\u001b[0m in \u001b[0;36mfind_similarity1\u001b[0;34m(word1, word2, sim_measure)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msim_measure\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"lin_similarity\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrown_ic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mpossible_similarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mlin_similarity\u001b[0;34m(self, synset1, synset2, ic, verbose)\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlin_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msynset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m     \u001b[0mlin_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mlin_similarity\u001b[0;34m(self, other, ic, verbose)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \"\"\"\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         \u001b[0mic1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcs_ic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lcs_ic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlcs_ic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mic1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mic2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m_lcs_ic\u001b[0;34m(synset1, synset2, ic, verbose)\u001b[0m\n\u001b[1;32m   2433\u001b[0m     \"\"\"\n\u001b[1;32m   2434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msynset1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msynset2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2435\u001b[0;31m         raise WordNetError(\n\u001b[0m\u001b[1;32m   2436\u001b[0m             \u001b[0;34m\"Computing the least common subsumer requires \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m             \u001b[0;34m\"%s and %s to have the same part of speech.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msynset1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWordNetError\u001b[0m: Computing the least common subsumer requires Synset('bird.n.01') and Synset('cock.v.01') to have the same part of speech."
          ]
        }
      ],
      "source": [
        "lin_sim = []\n",
        "\n",
        "\n",
        "for x in range(df.shape[0]):\n",
        "  sims = find_similarity1(df.iloc[x,0], df.iloc[x,1], \"lin_similarity\")\n",
        "  lin_sim.append(sims)\n",
        "\n",
        "lin_sim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_similarity1(df.iloc[0,0], df.iloc[0,1], \"res_similarity\")"
      ],
      "metadata": {
        "id": "XOcd6CPcYp9G",
        "outputId": "dd898e3b-748c-4f16-e09a-906904ad1d6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.475167326283652"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQHZU9SgoIrB"
      },
      "source": [
        "### 3.3\n",
        "Correlate each of the calculated sets of scores with each other and with the human judgements (I suggest you use scipy.stats.spearmanr() or pandas for this)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCqwepdfHiEv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShWvIn3EHiEv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRDB4MovHiEw"
      },
      "source": [
        "### 3.4\n",
        "\n",
        "What do you conclude?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGpo0EMcHiEw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuTbzhLtoIrC"
      },
      "source": [
        "## 4 Distributional Similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04JGl4P_HiEw"
      },
      "source": [
        "We are going to be using some pre-computed Word2Vec embeddings.  We will be learning about how these are computed in a few weeks time.  For now, you can assume they in some way capture the notion of distributional similarity discussed in this week's class: words which are used in similar ways will have similar vectors in this space.  You can download the embeddings here:\n",
        "\n",
        "https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
        "\n",
        "Note this is a very large file: 1.65GB zipped\n",
        "\n",
        "Or, if working on a lab computer, you can use the following full path:\n",
        "\n",
        "mac: /Volumes/teaching/Departments/Informatics/AdvancedNLP/GoogleNews-vectors-negative300.bin\n",
        "\n",
        "windows: //ad.susx.ac.uk/ITS/Teaching/Departments/Informatics/AdvancedNLP/GoogleNews-vectors-negative300.bin\n",
        "\n",
        "\n",
        "You should now be able to load them in to python using the following code (it may take a while to run this).  If working on a mac or your own machine, you may need to use conda or pip to install the gensim package into your environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCR86smeoIrC"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_hW3pk_oIrD"
      },
      "outputs": [],
      "source": [
        "#this cell may take a minute or more to run as it is loading a large model into memory\n",
        "#avoid re-running it unnecessarily\n",
        "filename=os.path.join(path,\"GoogleNews-vectors-negative300.bin\")\n",
        "mymodel =KeyedVectors.load_word2vec_format(filename,binary=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha2j2RMCHiEw"
      },
      "source": [
        "You can now query the model with calls to methods of mymodel as in the cells below.  Take time to think about what each call is doing and try some similar queries of your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "at68UApFoIrD"
      },
      "outputs": [],
      "source": [
        "mymodel.similarity('car','chicken')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwqnL-JDoIrD"
      },
      "outputs": [],
      "source": [
        "#this cell may crash your session on the basic CoLab as you might run out of RAM.\n",
        "#You probably need to be working on Anaconda on a reasonably powerful machine or have Colab Pro\n",
        "mymodel.most_similar(positive=['man'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqNGacJHoIrD"
      },
      "outputs": [],
      "source": [
        "mymodel.similarity('noon','string')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaZ_F_w2oIrD"
      },
      "outputs": [],
      "source": [
        "mymodel['man']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8mQDdaZoIrE"
      },
      "source": [
        "## 4.1\n",
        "Repeat the tasks in Section 3 using similarity scores from the word2vec model.  Make sure you correlate the word2vec similarities with the human synonymy judgements and the wordnet similarity scores.  What do you conclude?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lF7D8OqqHiEx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6sGSYDKoIrE"
      },
      "source": [
        "### 4.2\n",
        "* Which measure has the highest correlation with human synonymy judgements now?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYbaXKIBHiEx"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0irgjNXHiEx"
      },
      "source": [
        "## 5 Extension\n",
        "See the pdf for instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWgftVYWoIrI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Po08oF1PoIrC",
        "B6sGSYDKoIrE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}